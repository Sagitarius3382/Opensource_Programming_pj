{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b058577-9fe6-4819-b2a9-a84405aaddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time    # 랜덤 딜레이시\n",
    "import random  # 랜덤 딜레이시\n",
    "import re  # 정규 표현식\n",
    "import pandas as pd # Pandas df 사용\n",
    "\n",
    "# ----------------------\n",
    "# 1. 상수 정의 (PC 버전)\n",
    "# ----------------------\n",
    "BASE_URL = \"https://gall.dcinside.com\"\n",
    "\n",
    "# User-Agent 목록 정의(랜덤선택)\n",
    "USER_AGENT_LIST = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 14_2_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "]\n",
    "\n",
    "\n",
    "def get_regular_post_data(gallery_id: str, gallery_type: str = \"minor\", search_keyword: str = \"\", search_option: int = 0, start_page: int = 1, end_page: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    PC 갤러리 페이지에서 게시물의 제목과 내용을 추출하여 DataFrame으로 반환합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_list = []\n",
    "\n",
    "    # 갤러리 종류별 주소 설정\n",
    "    if gallery_type == \"minor\":\n",
    "        gallery_type_url = \"/mgallery/board/lists\"\n",
    "    elif gallery_type == \"major\":\n",
    "        gallery_type_url = \"/board/lists\"\n",
    "    elif gallery_type == \"mini\":\n",
    "        gallery_type_url = \"/mini/board/lists\"\n",
    "    else:\n",
    "        print(\"gallery_type 인자가 잘못 되었습니다. 빈 df를 반환합니다.\")\n",
    "        return pd.DataFrame(data_list)\n",
    "    \n",
    "    for i in range(start_page, end_page + 1):\n",
    "        \n",
    "        # ----------------------\n",
    "        # 1단계: 목록 페이지 요청 및 파싱\n",
    "        # ----------------------\n",
    "        \n",
    "        params = {'id': gallery_id, 'page': i}\n",
    "\n",
    "        # 검색 주소 조립 시 필요한 파라미터 정의\n",
    "        # ex) https://gall.dcinside.com/mgallery/board/lists/?id={GalleryID}&s_type={search_option}&s_keyword={search_keyword}\n",
    "        if search_keyword:\n",
    "            # PC 검색 파라미터 사용\n",
    "            params['search_pos'] = ''\n",
    "\n",
    "            # 검색 옵션 별 주소 설정\n",
    "            if search_option == 0:\n",
    "                params['s_type'] = 'search_subject_memo'\n",
    "            elif search_option == 1:\n",
    "                params['s_type'] = 'search_subject'\n",
    "            elif search_option == 2:\n",
    "                params['s_type'] = 'search_memo'\n",
    "            else:\n",
    "                print(\"search_option 인수가 잘못 되었습니다. 기본값인 0(제목, 내용 검색)으로 설정됩니다.\")\n",
    "                params['s_type'] = 'search_subject_memo'\n",
    "                \n",
    "            params['s_keyword'] = search_keyword\n",
    "\n",
    "        # User-Agent 설정\n",
    "        user_agent = random.choice(USER_AGENT_LIST)\n",
    "        headers = {'User-Agent': user_agent}\n",
    "\n",
    "        # try-except\n",
    "        try:\n",
    "            print(f\"--- 갤러리 목록 페이지 {i} 요청 중 ---\")\n",
    "            full_url = BASE_URL + gallery_type_url\n",
    "            response = requests.get(full_url, params=params, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"목록 페이지 {i} 요청 실패: {e}. 다음 페이지로 이동합니다.\")\n",
    "            time.sleep(random.uniform(2, 4))\n",
    "            continue\n",
    "\n",
    "        # lxml 파서 사용(HTML 대신)\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        \n",
    "        # 글 목록 구조: <tbody> 내의 <tr>\n",
    "        article_list = soup.find('tbody').find_all('tr', {'data-type': ['icon_pic', 'icon_txt']})\n",
    "        \n",
    "        # 기본 공지, 광고글 필터링\n",
    "        # 일반적으로 없어도 무관하지만 공백 검색시 포함됨\n",
    "        filtered_articles = []\n",
    "        for tr_item in article_list:\n",
    "            writer_tag = tr_item.find('td', class_='gall_writer')\n",
    "            is_operator_post = writer_tag and writer_tag.get('user_name') == '운영자'\n",
    "            is_notice = tr_item.get('data-type') == 'icon_notice'\n",
    "            \n",
    "            if not is_operator_post and not is_notice:\n",
    "                filtered_articles.append(tr_item)\n",
    "                \n",
    "        if not filtered_articles:\n",
    "             print(f\"페이지 {i}에서 유효한 일반 게시물이 없습니다. 크롤링 종료.\")\n",
    "             break \n",
    "\n",
    "\n",
    "        # ----------------------\n",
    "        # 2단계: 개별 게시물 접근 및 내용 추출 \n",
    "        # ----------------------\n",
    "        for tr_item in filtered_articles:\n",
    "            \n",
    "            title_tag = tr_item.find('a', href=True)\n",
    "            if not title_tag: continue\n",
    "\n",
    "            title_raw = title_tag.text.strip()\n",
    "            relative_url = title_tag['href']\n",
    "\n",
    "            # 게시글 ID 저장\n",
    "            post_id_match = re.search(r'&no=(\\d+)', relative_url)\n",
    "            post_id = post_id_match.group(1) if post_id_match else None\n",
    "\n",
    "            # 게시글 ID 오류 시 건너뛰기\n",
    "            if not post_id:\n",
    "                print(f\"    -> 오류: 게시물 번호 추출 실패 ({BASE_URL + relative_url}). 건너뜁니다.\")\n",
    "                continue\n",
    "            \n",
    "            # href 절대 경로/상대 경로 모두 대응 (없어도 솔직히 문제 없을듯?)\n",
    "            if relative_url.startswith('http'):\n",
    "                full_url = relative_url\n",
    "            else:\n",
    "                full_url = BASE_URL + relative_url\n",
    "\n",
    "            # 랜덤 딜레이\n",
    "            time.sleep(random.uniform(3, 5))\n",
    "            \n",
    "            # 게시물 본문 요청\n",
    "            try:\n",
    "                print(f\"   -> 게시물 요청: {title_raw[:20]}...\")\n",
    "                article_user_agent = random.choice(USER_AGENT_LIST)\n",
    "                article_headers = {'User-Agent': article_user_agent}\n",
    "                article_response = requests.get(full_url, headers=article_headers, timeout=10)\n",
    "                article_response.raise_for_status()\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"   -> 게시물 요청 실패 ({full_url}): {e}\")\n",
    "                continue\n",
    "            \n",
    "            article_soup = BeautifulSoup(article_response.content, 'lxml') # lxml 사용\n",
    "\n",
    "            # 본문 추출 클래스: 'write_div'\n",
    "            article_contents_tag = article_soup.find('div', class_='write_div')\n",
    "            article_contents = \"\"\n",
    "            if article_contents_tag:\n",
    "                # 텍스트만 추출\n",
    "                article_contents = article_contents_tag.get_text(strip=True)\n",
    "            \n",
    "            # ----------------------\n",
    "            # 3단계: 데이터 클리닝 및 저장\n",
    "            # ----------------------\n",
    "            \n",
    "            # 제목과 게시글에서 url 제거\n",
    "            pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$\\-@\\.&+:/?=]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "            repl = ''\n",
    "            title_clean = re.sub(pattern=pattern, repl=repl, string=title_raw).strip()\n",
    "            article_contents_clean = re.sub(pattern=pattern, repl=repl, string=article_contents).strip()\n",
    "            \n",
    "            # '- dc official App' 제거\n",
    "            article_contents_clean = article_contents_clean.replace('- dc official App', '').strip()\n",
    "            \n",
    "            \n",
    "            if article_contents_clean:\n",
    "                data_list.append({\n",
    "                    'PostID': post_id,\n",
    "                    'Title': title_clean,\n",
    "                    'Content': article_contents_clean,\n",
    "                    'GalleryID': gallery_id,\n",
    "                    'URL': full_url\n",
    "                })\n",
    "\n",
    "    # ----------------------\n",
    "    # 4단계: 리스트를 최종 DataFrame으로 변환 및 중복 제거\n",
    "    # ----------------------\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    # PostID를 기준으로 중복 행 제거 (페이지가 겹쳐서 재수집된 게시물 제거)\n",
    "    if not df.empty:\n",
    "        df = df.drop_duplicates(subset=['GalleryID', 'PostID'], keep='first')\n",
    "        print(f\"\\n--- 크롤링 완료 및 중복 제거 ---\")\n",
    "        print(f\"총 수집된 게시물 수: {len(data_list)}개\")\n",
    "        print(f\"중복 제거 후 최종 게시물 수: {len(df)}개\")\n",
    "             \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73a09adb-559d-454c-acb9-deb966c56f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 갤러리 목록 페이지 1 요청 중 ---\n",
      "   -> 게시물 요청: 스포)생각해보니 다이아린이 빛나파츠면...\n",
      "   -> 게시물 요청: 대충 빛나 자오 다이아린아니면 빛나 ...\n",
      "   -> 게시물 요청: 스포)빛나 2돌하면 다이아린 필요 없...\n",
      "   -> 게시물 요청: 스포)빛나 배포에 자오 픽업하려는 큰...\n",
      "   -> 게시물 요청: 스포)소신발언)빛나 언니겜 캐릭들 스...\n",
      "   -> 게시물 요청: 솔직히 이미 파츠는 누구나다알잖아...\n",
      "   -> 게시물 요청: 스포)빛나 1궁때 모션 좀 찍싸는거 ...\n",
      "   -> 게시물 요청: 스포)유출러) 엽빛나 궁 5090으로...\n",
      "   -> 게시물 요청: 본인 빛나한테 애정느끼고 뽑고싶은이유...\n",
      "   -> 게시물 요청: 근데 자오 엽빛나 외에도 쓸만함?...\n",
      "   -> 게시물 요청: 스포)이거 두리안같긴하네...\n",
      "   -> 게시물 요청: 엽빛나 VS 엘리스 2 제인 2...\n",
      "   -> 게시물 요청: 그럼 정릴 해 보자면.......\n",
      "   -> 게시물 요청: 나 시드맘인데...\n",
      "   -> 게시물 요청: 스포)그럼 엽빛나팟 방부 비르크블리크...\n",
      "   -> 게시물 요청: 스포)빛나 전용 방부인가봐...\n",
      "   -> 게시물 요청: 엽빛나 느끼하다 <- 걍 워딩이 개웃...\n",
      "   -> 게시물 요청: 빛나 약간 남의 여동생속성이라 귀여운...\n",
      "   -> 게시물 요청: 스포)이거 빛나아님?...\n",
      "   -> 게시물 요청: 그래서 엽빛나는 미아즈마 보스도 잘 ...\n",
      "--- 갤러리 목록 페이지 2 요청 중 ---\n",
      "   -> 게시물 요청: 빛나 약간 남의 여동생속성이라 귀여운...\n",
      "   -> 게시물 요청: 스포)이거 빛나아님?...\n",
      "   -> 게시물 요청: 그래서 엽빛나는 미아즈마 보스도 잘 ...\n",
      "   -> 게시물 요청: 빛나랑 약간 운명을 느끼네...\n",
      "   -> 게시물 요청: 나 고민있는데 조언좀......\n",
      "   -> 게시물 요청: 스포)아무리 그래도 시트코보단 시드 ...\n",
      "   -> 게시물 요청: 옆빛나 창년치매였노...\n",
      "   -> 게시물 요청: 빛나도 검은가지였으면 좋았을텐데...\n",
      "   -> 게시물 요청: 옆빛나 개웃기네 ㅋㅋ...\n",
      "   -> 게시물 요청: 빛나 2돌해도 다이아린이 고점파츠 아...\n",
      "   -> 게시물 요청: 빛나...\n",
      "   -> 게시물 요청: 스포)빛나 나올 때 이 영상도 나오는...\n",
      "   -> 게시물 요청: 빛나 다이아린 쓰면 안됨...\n",
      "   -> 게시물 요청: 스포)다이아린 빛나 파츠아니면 거르껀...\n",
      "   -> 게시물 요청: 빛나 설명 <- ㅈㄴ 지루하고 현학적...\n",
      "   -> 게시물 요청: 스포)빛나 풀돌에 미야비처럼 추가타나...\n",
      "   -> 게시물 요청: 팩트는 빛나는 점점 더 강해지고 있다...\n",
      "   -> 게시물 요청: 빛나한테 억지로 당하는 의현이 보고싶...\n",
      "   -> 게시물 요청: 스포)빛나한테 꼬추밟히고싶네........\n",
      "   -> 게시물 요청: 스포)와 근데 빛나 2돌아니면 개불편...\n",
      "\n",
      "--- 크롤링 완료 및 중복 제거 ---\n",
      "총 수집된 게시물 수: 38개\n",
      "중복 제거 후 최종 게시물 수: 35개\n",
      "최종 수집된 게시물 수: 35개\n",
      "\n",
      "데이터가 dcinside_data.csv 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: 함수 실행 및 결과 확인\n",
    "\n",
    "# 1. 갤러리 ID와 검색어 설정\n",
    "gallery_id_target = 'zenless_zone_zero'\n",
    "search_keyword_target = '빛나'\n",
    "start_page_num = 1\n",
    "end_page_num = 2 # 1페이지부터 n페이지까지 수집\n",
    "\n",
    "# 2. 함수 호출\n",
    "results_df = get_regular_post_data(\n",
    "    gallery_id=gallery_id_target, \n",
    "    gallery_type=\"minor\",\n",
    "    search_keyword=search_keyword_target, \n",
    "    start_page=start_page_num, \n",
    "    end_page=end_page_num\n",
    ")\n",
    "\n",
    "# 3. 결과 출력 및 확인\n",
    "print(f\"최종 수집된 게시물 수: {len(results_df)}개\")\n",
    "\n",
    "# 주피터 노트북은 head()를 호출하면 DataFrame을 테이블 형태로 예쁘게 출력합니다.\n",
    "results_df.head()\n",
    "\n",
    "# CSV 저장 (선택 사항)\n",
    "if not results_df.empty:\n",
    "    results_df.to_csv(f\"{gallery_id_target}_{search_keyword_target}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"\\n데이터가 dcinside_data.csv 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d7ebf-0fa4-483b-a1f8-128c98c5ab9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
