import os
import json
import time
import re
import pandas as pd
import streamlit as st
import google.generativeai as genai
import concurrent.futures
import altair as alt  # ì›í˜• ê·¸ë˜í”„ ìƒì„±ì„ ìœ„í•œ ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
from dotenv import load_dotenv

# --------------------------------------------------------------------------
# 1. ì´ˆê¸° ì„¤ì • ë° í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# --------------------------------------------------------------------------
load_dotenv()

st.set_page_config(
    page_title="Community Insight Bot",
    page_icon="ğŸ•µï¸â€â™‚ï¸",
    layout="wide"
)

# ìƒˆë¡œìš´ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from src.crawler_wrapper import search_community
    from src.preprocessor import filter_hate_speech
except ImportError as e:
    st.error(f"í•„ìˆ˜ ëª¨ë“ˆì„ ì„í¬íŠ¸í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

# --------------------------------------------------------------------------
# 2. ì‚¬ì´ë“œë°” ì„¤ì • (API ìƒíƒœ í‘œì‹œ)
# --------------------------------------------------------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    api_key = os.getenv("API_KEY")
    model_name = os.getenv("MODEL")

    if api_key and model_name:
        st.success("ğŸŸ¢ API ì—°ë™ ì •ìƒ")
        st.markdown(f"**ì‚¬ìš© ëª¨ë¸:** `{model_name}`")
    else:
        st.error("ğŸ”´ API ì—°ë™ ì‹¤íŒ¨")
        if not api_key:
            st.warning("API í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        if not model_name:
            st.warning("ëª¨ë¸ ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    st.markdown("---")
    st.info("AIê°€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ì»¤ë®¤ë‹ˆí‹°(DC/Arca)ë¥¼ ì„ ì •í•˜ê³  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
    st.info("Tip) ë””ì‹œì¸ì‚¬ì´ë“œ ê²€ìƒ‰ì˜ ê¸°ë³¸ê°’ì€ í†µí•©ê²€ìƒ‰ì´ì§€ë§Œ, ê°¤ëŸ¬ë¦¬ ê²€ìƒ‰ì„ ì›í•  ê²½ìš° ì±„ë„ idì™€ í•¨ê»˜ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: í—¤ë“œí° ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬(id=newheadphone)ì—ì„œ ê²€ìƒ‰í•´ì¤˜.)")
    st.info("Tip) ë””ì‹œì¸ì‚¬ì´ë“œ í†µí•©ê²€ìƒ‰ì˜ ê¸°ë³¸ê°’ì€ ìµœì‹ ìˆœì´ì§€ë§Œ, ì •í™•ë„ ìˆœìœ¼ë¡œ ê²€ìƒ‰í•´ë‹¬ë¼ê³  í•˜ë©´ ì •í™•ë„ìˆœìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.")
    st.caption("Powered by Google Gemini")

# --------------------------------------------------------------------------
# 3. Gemini ëª¨ë¸ ë¡œë“œ 
# --------------------------------------------------------------------------
@st.cache_resource
def get_gemini_model():
    """
    Gemini ëª¨ë¸ ë¡œë“œ (ìºì‹± ì ìš©)
    """
    YOUR_API_KEY = os.getenv("API_KEY")
    if not YOUR_API_KEY:
        st.stop()

    YOUR_MODEL = os.getenv("MODEL")
    if not YOUR_MODEL:
        st.stop()
        
    genai.configure(api_key=YOUR_API_KEY)
    
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    
    return genai.GenerativeModel(YOUR_MODEL, safety_settings=safety_settings)

# --------------------------------------------------------------------------
# 4. í•µì‹¬ ë¡œì§ í•¨ìˆ˜ 
# --------------------------------------------------------------------------

def get_search_plan(user_input):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.
    """
    model = get_gemini_model()
    
    system_instruction = """
    ë„ˆëŠ” 'ì»¤ë®¤ë‹ˆí‹° í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ìœ„í•œ ê²€ìƒ‰ ì„¤ê³„ì'ì•¼. 
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ ì–´ë–¤ ì»¤ë®¤ë‹ˆí‹°(DCInside, ArcaLive ë‘˜ ì¤‘ í•˜ë‚˜)ë¥¼ ì–´ë–¤ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í• ì§€ êµ¬ì²´ì ì¸ ê³„íšì„ ì„¸ì›Œì¤˜.
    
    [í•„ìˆ˜ ê·œì¹™]
    1. ì‚¬ìš©ìê°€ "ì—¬ë¡ ", "ë°˜ì‘", "í‰ê°€" , "ì˜ê²¬" , "ê·¼í™©" ë“± í‚¤ì›Œë“œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•œ ê²ƒì„ ë¬¼ìœ¼ë©´ mode="search"ë¡œ ì„¤ì •í•´.
    2. **ê²€ìƒ‰ì–´(keyword)ëŠ” ê³µì‹ ëª…ì¹­ë³´ë‹¤ ì‹¤ì œë¡œ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ë§ì´ ì“°ì´ëŠ” 'ë‹¨ì–´ì˜ ì¼ë¶€ë¶„', 'ì€ì–´'ë‚˜ 'ì¤„ì„ë§'ì„ ìš°ì„ ì ìœ¼ë¡œ ì„ íƒí•´.** (ì˜ˆ: ê°¤ëŸ­ì‹œ S25 -> S25, ë¸”ë£¨ ì•„ì¹´ì´ë¸Œ -> ë¸”ì•„, ë¦¬ê·¸ì˜¤ë¸Œë ˆì „ë“œ -> ë¡¤, ë§¨ì²´ìŠ¤í„° ìœ ë‚˜ì´í‹°ë“œ -> ë§¨ìœ )
    3. **[íƒ€ê²Ÿ ì„ ì •]** íŠ¹ì • ì‚¬ì´íŠ¸ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´, í•´ë‹¹ ì£¼ì œê°€ í™œë°œí•œ ê³³ì„ ìë™ìœ¼ë¡œ íŒë‹¨í•˜ë˜ **ì˜ ëª¨ë¥´ê² ê±°ë‚˜ ëŒ€ì¤‘ì ì¸ ê²Œì„/ì´ìŠˆë¼ë©´ ["dc", "arca"] ë‘ ê³³ì— ëŒ€í•´ taskë¥¼ ì´ 2ê°œ ìƒì„±í•´ì•¼í•´.**
    4. **task['options']ì˜ 'gallery_id'ì™€ 'gallery_type'ëŠ” ì‚¬ìš©ìê°€ íŠ¹ë³„íˆ ê°¤ëŸ¬ë¦¬ë¥¼ ì§€ì •í•˜ì§€ ì•ŠëŠ” ì´ìƒ null ê°’ì´ì•¼(í†µí•©ê²€ìƒ‰ ì´ìš©).**
    5. ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶°ì„œ ë°˜í™˜í•´ì¤˜.

    [mode íŒë‹¨ ê¸°ì¤€]
    1. "search": íŠ¹ì • ê²Œì„, ì¸ë¬¼, ì‚¬ê±´ ë“± í‚¤ì›Œë“œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•œ ì£¼ì œì— ëŒ€í•´ ë¬»ëŠ” ê²½ìš°.
    2. "clarify": í‚¤ì›Œë“œê°€ ë„ˆë¬´ ëª¨í˜¸í•´ì„œ(ì˜ˆ: 'í—¤ë¥´íƒ€'ê°€ ì‘ê°€ í—¤ë¥´íƒ€ ë®ëŸ¬ì¸ì§€, ì¶•êµ¬íŒ€ í—¤ë¥´íƒ€ BSCì¸ì§€, ë¶•ê´´ ìŠ¤íƒ€ë ˆì¼ ê²Œì„ì˜ ë“±ì¥ì¸ë¬¼ í—¤ë¥´íƒ€ì¸ì§€ ë¶ˆë¶„ëª…í•¨) ê²€ìƒ‰ ëŒ€ìƒì„ í™•ì •í•  ìˆ˜ ì—†ëŠ” ê²½ìš°.
    3. "chat": ë‹¨ìˆœ ì¸ì‚¬, ì¡ë‹´, í˜¹ì€ ë¶„ì„ê³¼ ê´€ë ¨ ì—†ëŠ” ëŒ€í™”.

    [JSON ì¶œë ¥ í˜•ì‹]
    {
        "mode": "search" | "clarify" | "chat", 
        "reply_message": "clarify" | "chat" ëª¨ë“œì¼ ë•Œ ì‚¬ìš©ìì—ê²Œ í•  ë§,
        "tasks": [
            {
                "target_source": "dc" | "arca",
                "keyword": "ê²€ìƒ‰ì–´: ë‹¨ì–´ì˜ ì¼ë¶€ë¶„, ì¤„ì„ë§, ì€ì–´ë¥¼ ì ê·¹ì ìœ¼ë¡œ ì‚¬ìš©. íŠ¹ì • ì£¼ì œì˜ ê°¤ëŸ¬ë¦¬ ê²€ìƒ‰ ì‹œ ì£¼ì œ ê´€ë ¨ ë‹¨ì–´ëŠ” ì œê±°. (ì˜ˆ: ì›ì‹  ê°¤ëŸ¬ë¦¬ ê²€ìƒ‰ ì‹œ, 'ì›ì‹  í•„ìˆ˜ìº' -> 'í•„ìˆ˜ìº')",
                "options": {
                    # dc, arca ê³µí†µ íŒŒë¼ë¯¸í„°
                    "end_page": "ì¢…ë£Œ í˜ì´ì§€ (ì»¤ë®¤ë‹ˆí‹° í•˜ë‚˜ë§Œ íƒìƒ‰í•  ë•ŒëŠ” '2', ë‘ ê³³ ëª¨ë‘(len(tasks) == 2)ì¼ ë•ŒëŠ” '1')",

                    # "target_source" == "dc" ì¼ ë•Œ ì…ë ¥í•  ë‚´ìš©
                    "gallery_id": "ê¸°ë³¸ê°’ì€ null. ì‚¬ìš©ì ìš”ì²­ì´ ìˆì„ ì‹œ í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•  ê°¤ëŸ¬ë¦¬ì˜ ê°¤ëŸ¬ë¦¬ ID (ì˜ˆ: 'maplestory_new', 'leagueoflegends6', 'chzzk').",
                    "gallery_type": "ê¸°ë³¸ê°’ì€ null. ì‚¬ìš©ìì˜ ìš”ì²­ì´ ìˆì„ ì‹œ gallery_idê°’ì— í•´ë‹¹í•˜ëŠ” ê°¤ëŸ¬ë¦¬ì˜ ì¢…ë¥˜ë¥¼ ê¸°ì¬. ('major' | 'minor').", 
                    "sort_type": ê¸°ë³¸ê°’ì€ "latest". ì‚¬ìš©ìì˜ 'ì •í™•ë„ ìˆœ' ìš”ì²­ì´ ìˆì„ ì‹œ "accuracy".

                    # "target_source" == "arca" ì¼ ë•Œ ì…ë ¥í•  ë‚´ìš©
                    "channel_id": "breaking" (í•­ìƒ í†µí•©ê²€ìƒ‰ ì‚¬ìš©),
                }
            }
        ]
    }
    """
    
    try:
        response = model.generate_content(
            f"{system_instruction}\n\nUser Input: {user_input}",
            generation_config={"response_mime_type": "application/json"}
        )
        if response.parts:
            return json.loads(response.text)
        else:
            return {"mode": "chat", "reply_message": "ì£„ì†¡í•©ë‹ˆë‹¤. ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "tasks": []}
    except Exception as e:
        return {"mode": "chat", "reply_message": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", "tasks": []}

def execute_crawling(tasks):
    all_results = []
    
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_to_task = {}
        for task in tasks:
            target = task.get("target_source")
            keyword = task.get("keyword")
            options = task.get("options", {})
            
            print(f"[DEBUG] Crawling Task: {target} - {keyword}")
            future = executor.submit(search_community, target, keyword, **options)
            future_to_task[future] = task

        # [ìˆ˜ì •] ëª¨ë“  íƒœìŠ¤í¬ê°€ 'ì™„ì „íˆ' ëë‚  ë•Œê¹Œì§€ ëª…ì‹œì ìœ¼ë¡œ ëŒ€ê¸° (wait)
        # return_when=ALL_COMPLETEDë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ë‚˜ë¼ë„ ì‹¤í–‰ ì¤‘ì´ë©´ ë„˜ì–´ê°€ì§€ ì•ŠìŒ
        if future_to_task:
            concurrent.futures.wait(future_to_task.keys(), return_when=concurrent.futures.ALL_COMPLETED)
            
        # ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œëœ í›„ ê²°ê³¼ ìˆ˜ì§‘
        for future in future_to_task:
            try:
                df = future.result()
                if not df.empty:
                    df["Source"] = future_to_task[future].get("target_source")
                    df["Keyword"] = future_to_task[future].get("keyword")
                    all_results.append(df)

            except Exception as e:
                print(f"[DEBUG] Error: {e}", flush=True)

    if all_results:
        # [ìˆ˜ì •] ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ë°ì´í„°ë¥¼ ê³ ë¥´ê²Œ ì„ê¸° (Interleaving)
        # ê° ë°ì´í„°í”„ë ˆì„ì— ìˆœìœ„(Rank)ë¥¼ ë§¤ê²¨ì„œ, 1ë“±ë¼ë¦¬, 2ë“±ë¼ë¦¬ ëª¨ì´ë„ë¡ ì •ë ¬
        for df in all_results:
            df['__rank'] = range(len(df))
        
        final_df = pd.concat(all_results, ignore_index=True)
        # Rank ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì†ŒìŠ¤ ê°„ ê· í˜• ë§ì¶¤ (ì˜ˆ: DC 1ìœ„ -> Arca 1ìœ„ -> DC 2ìœ„ ...)
        final_df = final_df.sort_values('__rank').drop(columns=['__rank']).reset_index(drop=True)
        
        return final_df
    else:
        return pd.DataFrame()

def generate_report(user_input, df):
    model = get_gemini_model()
    
    if df.empty: return None
        
    summary_text = ""
    cols = {c.lower(): c for c in df.columns}
    title_col = cols.get('title', 'Title')
    content_col = cols.get('content', 'Content')

    # ì¸ë±ìŠ¤ 1ë¶€í„° ì‹œì‘ (30ê°œ ì œí•œ)
    for i, (idx, row) in enumerate(df.head(30).iterrows()):
        title = row.get(title_col, "No Title")
        content = str(row.get(content_col, ""))[:150]
        summary_text += f"[ID: {i + 1}] {title}: {content}\n"
        
    prompt = f"""
    ë‹¹ì‹ ì€ ì»¤ë®¤ë‹ˆí‹° ì—¬ë¡  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    
    [ì‚¬ìš©ì ì§ˆë¬¸]
    {user_input}
    
    [ìˆ˜ì§‘ëœ ë°ì´í„° ìš”ì•½ (ID í¬í•¨)]
    {summary_text}
    
    ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    **ğŸ”¥ [ì¤‘ìš” ì§€ì¹¨] ğŸ”¥**
    ë³´ê³ ì„œì˜ ë¬¸ì¥ì´ë‚˜ í•µì‹¬ì ì¸ ì—¬ë¡ (ê¸ì •/ë¶€ì • ìš”ì†Œ)ì„ ì–¸ê¸‰í•  ë•ŒëŠ”, í•´ë‹¹ ë‚´ìš©ì˜ ê·¼ê±°ê°€ ëœ [ìˆ˜ì§‘ëœ ë°ì´í„° ìš”ì•½]ì˜ **ê²Œì‹œë¬¼ IDë¥¼ ë°˜ë“œì‹œ ê´„í˜¸ ì•ˆì— [ID] í˜•íƒœë¡œ ëª…ì‹œ**í•´ ì£¼ì„¸ìš”.
    * **ì˜ˆì‹œ:** "ëŒ€ë¶€ë¶„ì˜ ìœ ì €ê°€ ì¸í„°í˜ì´ìŠ¤ì˜ í¸ì˜ì„±ì„ ë†’ì´ í‰ê°€í–ˆìŠµë‹ˆë‹¤ [1, 5, 10]."
    * **ì˜ˆì‹œ:** "ê°€ê²© ì •ì±…ì— ëŒ€í•œ ë¶ˆë§Œì´ ë‹¤ìˆ˜ ì œê¸°ë˜ì—ˆìŠµë‹ˆë‹¤ [2, 4, 11]."
    
    [ë³´ê³ ì„œ í¬í•¨ í•­ëª©]
    1. **3ì¤„ ìš”ì•½**: ì „ì²´ì ì¸ ì—¬ë¡ ì˜ í•µì‹¬ ìš”ì•½
    2. **ê¸ì • ì—¬ë¡ **: ìœ ì €ë“¤ì´ ê¸ì •ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ìš”ì†Œ
    3. **ë¶€ì • ì—¬ë¡ **: ìœ ì €ë“¤ì´ ë¶ˆë§Œì´ë‚˜ ë¹„íŒì„ ì œê¸°í•˜ëŠ” ìš”ì†Œ
    4. **ì£¼ìš” ë…¼ìŸ**: í˜„ì¬ ê°€ì¥ ëœ¨ê±°ìš´ ê°ìë‚˜ ë…¼ìŸê±°ë¦¬
    5. **ì¢…í•© í‰ê°€**: ê²°ë¡  ë° ì œì–¸
    
    [íŠ¹ë³„ ì§€ì‹œì‚¬í•­ - ë°ì´í„° êµ¬ì¡°]
    **ì¤‘ìš”:** ë³´ê³ ì„œ ë³¸ë¬¸ ì‘ì„±ì´ ëª¨ë‘ ëë‚˜ë©´, ë°˜ë“œì‹œ `__REF_DATA__` ë¼ëŠ” êµ¬ë¶„ìë¥¼ ì¶œë ¥í•˜ê³ , ê·¸ ë’¤ì— **JSON í˜•ì‹**ìœ¼ë¡œ ì•„ë˜ ì •ë³´ë“¤ì„ ì¶œë ¥í•´ì£¼ì„¸ìš”.
    
    1. **reference_ids**: ë¶„ì„ì— ê°€ì¥ ì˜ì–‘ê°€ê°€ ë†’ì•˜ë˜ ê¸€ì˜ ID (ìµœëŒ€ 3ê°œ, ìˆ«ì ë¦¬ìŠ¤íŠ¸)
    2. **sentiment_counts**: ì „ì²´(ìµœëŒ€ 30ê°œ) ê¸€ì— ëŒ€í•œ ê°ì„± ë¶„ì„ í†µê³„. ê°ê°ì˜ ê¸€ì— ëŒ€í•´ ("Positive"|"Negative"|"Neutral")ì„ íŒë‹¨í•¨. (ê¸ì • ë¶€ì • íŒë‹¨ì´ ë¶ˆê°€ëŠ¥í•  ê²½ìš°ì—ëŠ” "Neutral"ë¡œ íŒë‹¨)
    3. **topic_counts**: ì „ì²´(ìµœëŒ€ 30ê°œ) ê¸€ì—ì„œ ì£¼ë¡œ ë‹¤ë¤„ì§„ ìƒìœ„ í‚¤ì›Œë“œ 3~5ê°œì™€ ê·¸ ë¹ˆë„ìˆ˜
    
    __REF_DATA__
    {{
        "reference_ids": [1, 5, 10],
        "sentiment_counts": {{ "Positive": 12, "Negative": 8, "Neutral": 10 }},
        "topic_counts": {{ "ê²Œì„í”Œë ˆì´": 15, "ìŠ¤í† ë¦¬": 8, "ìš´ì˜": 7 }}
    }}
    """
    
    return model.generate_content(prompt, stream=True)

# --------------------------------------------------------------------------
# 5. ë©”ì¸ ë¡œì§ 
# --------------------------------------------------------------------------
st.title("ğŸ•µï¸â€â™‚ï¸ Community Insight Bot")
st.caption("AIê°€ ìë™ìœ¼ë¡œ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ì„ ì •í•˜ê³  ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ ì •ë³´ì™€ ì—¬ë¡ ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

# [ëˆ„ì  ë°ì´í„° ê´€ë¦¬] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "sentiment_history" not in st.session_state:
    st.session_state.sentiment_history = {"Positive": 0, "Neutral": 0, "Negative": 0}
if "latest_topic_counts" not in st.session_state:
    st.session_state.latest_topic_counts = {}
if "messages" not in st.session_state:
    st.session_state.messages = []
    welcome_msg = "ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ í‚¤ì›Œë“œë¥¼ ë¬¼ì–´ë´ì£¼ì„¸ìš”. ì œê°€ ì»¤ë®¤ë‹ˆí‹° ì—¬ë¡ ì„ ë¶„ì„í•´ ë“œë¦´ê²Œìš”."
    st.session_state.messages.append({"role": "assistant", "content": welcome_msg})

# [CSS] ì±„íŒ…ì°½ ìŠ¤íƒ€ì¼ ì¡°ì • (ì±„íŒ… ì…ë ¥ì°½ì„ ì¢Œì¸¡ ì»¬ëŸ¼ ë„ˆë¹„ì— ë§ê²Œ ê³ ì •)
st.markdown(
    """
    <style>
    /* í™”ë©´ ë„ˆë¹„ê°€ ë„“ì„ ë•Œ (PC ë“±) ì±„íŒ… ì…ë ¥ì°½ì„ ì¢Œì¸¡ 60% ì˜ì—­ì— ë§ì¶¤ */
    @media (min-width: 768px) {
        div[data-testid="stChatInput"] {
            width: 58% !important; /* ì¢Œì¸¡ ì»¬ëŸ¼ ë¹„ìœ¨ì— ë§ê²Œ ì¡°ì • (gap ê³ ë ¤) */
            left: 21rem !important; /* ì‚¬ì´ë“œë°” ë„ˆë¹„(ê¸°ë³¸ê°’)ë§Œí¼ ë„ì›€ */
            margin-right: auto;
        }
        .stMain div[data-testid="stChatInput"] {
            width: 58% !important;
            left: auto !important;
            right: auto !important;
        }
    }
    </style>
    """,
    unsafe_allow_html=True
)

# --- í™”ë©´ ë ˆì´ì•„ì›ƒ ë¶„í•  (ì¢Œ: ì±„íŒ… / ìš°: í†µê³„) ---
chat_col, stat_col = st.columns([0.6, 0.4], gap="large")

# ëŒ€ì‹œë³´ë“œë¥¼ ë®ì–´ì“°ê¸° ìœ„í•´ st.empty()ë¡œ placeholder ìƒì„±
dashboard_placeholder = stat_col.empty()

# [ìš°ì¸¡] í†µê³„ ëŒ€ì‹œë³´ë“œ ë Œë”ë§ í•¨ìˆ˜
def render_stats_dashboard():
    # placeholder.container()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤ë²ˆ ë‚´ìš©ì„ ë®ì–´ì”€ (ì¤‘ë³µ ì¶œë ¥ ë°©ì§€)
    with dashboard_placeholder.container():
        st.markdown("### ğŸ“ˆ ì‹¤ì‹œê°„ ì—¬ë¡  ëŒ€ì‹œë³´ë“œ")
        
        # 1. ëˆ„ì  ê°ì„± ë¶„ì„ (ì›í˜• ê·¸ë˜í”„)
        total_sentiment = sum(st.session_state.sentiment_history.values())
        if total_sentiment > 0:
            st.markdown("#### ğŸ˜Š ëˆ„ì  ê°ì„± ë¹„ìœ¨")
            
            sentiment_df = pd.DataFrame([
                {"Category": "ğŸ˜Š ê¸ì •", "Count": st.session_state.sentiment_history["Positive"], "Color": "#4CAF50"}, # ì´ˆë¡
                {"Category": "ğŸ˜ ì¤‘ë¦½", "Count": st.session_state.sentiment_history["Neutral"], "Color": "#FFC107"},  # ë…¸ë‘
                {"Category": "ğŸ˜¡ ë¶€ì •", "Count": st.session_state.sentiment_history["Negative"], "Color": "#F44336"}   # ë¹¨ê°•
            ])
            
            # ë„ë„› ì°¨íŠ¸ ìƒì„±
            base = alt.Chart(sentiment_df).encode(
                theta=alt.Theta("Count", stack=True)
            )
            
            pie = base.mark_arc(outerRadius=120, innerRadius=60).encode(
                color=alt.Color("Category", 
                                scale=alt.Scale(domain=["ğŸ˜Š ê¸ì •", "ğŸ˜ ì¤‘ë¦½", "ğŸ˜¡ ë¶€ì •"], 
                                              range=["#66BB6A", "#FFCA28", "#EF5350"]),
                                legend=alt.Legend(title="ê°ì„± ìƒíƒœ", titleFontSize=12, labelFontSize=12)),
                order=alt.Order("Count", sort="descending"),
                tooltip=["Category", "Count", alt.Tooltip("Count", format=".0f")]
            )
            
            text = base.mark_text(radius=140).encode(
                text="Count",
                order=alt.Order("Count", sort="descending"),
                color=alt.value("black"),
                size=alt.value(16)
            )
            
            st.altair_chart(pie + text, use_container_width=True)
            
            col1, col2, col3 = st.columns(3)
            col1.metric("ê¸ì •", st.session_state.sentiment_history["Positive"])
            col2.metric("ì¤‘ë¦½", st.session_state.sentiment_history["Neutral"])
            col3.metric("ë¶€ì •", st.session_state.sentiment_history["Negative"])
            
        else:
            st.info("ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ë©´ í†µê³„ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

        st.markdown("---")

        # 2. í‚¤ì›Œë“œ ë¹ˆë„ (ê°€ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„)
        if st.session_state.latest_topic_counts:
            st.markdown("#### ğŸ”‘ ìµœì‹  í‚¤ì›Œë“œ ë¹ˆë„ (ìƒˆ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤)")
            
            topic_data = st.session_state.latest_topic_counts
            topic_df = pd.DataFrame(list(topic_data.items()), columns=['Keyword', 'Count'])
            topic_df = topic_df.sort_values(by='Count', ascending=False)
            
            bar_chart = alt.Chart(topic_df).mark_bar().encode(
                x=alt.X('Count', title='ë¹ˆë„ìˆ˜', axis=alt.Axis(titleFontSize=14, labelFontSize=12)),
                y=alt.Y('Keyword', sort='-x', title='í‚¤ì›Œë“œ', 
                        axis=alt.Axis(titleFontSize=14, labelFontSize=14, labelLimit=200)),
                color=alt.value("#7E57C2"),
                tooltip=['Keyword', 'Count']
            ).properties(
                height=300
            )
            
            text_bar = bar_chart.mark_text(
                align='left',
                baseline='middle',
                dx=3
            ).encode(
                text='Count'
            )
            
            st.altair_chart(bar_chart + text_bar, use_container_width=True)
            
        else:
            st.caption("ìµœê·¼ ê²€ìƒ‰ëœ í‚¤ì›Œë“œ í†µê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì´ˆê¸° ë Œë”ë§
render_stats_dashboard()

# [ì¢Œì¸¡] ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ (ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆ ì ìš©)
with chat_col:
    # [ë³€ê²½] ë©”ì‹œì§€ ì¶œë ¥ì„ ìœ„í•œ ê³ ì • ë†’ì´ ì»¨í…Œì´ë„ˆ ìƒì„±
    chat_container = st.container(height=950)
    
    with chat_container:
        # ì´ì „ ëŒ€í™” ì¶œë ¥
        for message in st.session_state.messages:
            avatar_img = "assets/purple_avatar.png" if message["role"] == "assistant" else None
            with st.chat_message(message["role"], avatar=avatar_img):
                st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ (í•˜ë‹¨ ê³ ì •)
if prompt := st.chat_input("ë¬´ì—‡ì„ ë¶„ì„í•´ ë“œë¦´ê¹Œìš”?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # [ë³€ê²½] ìƒˆë¡œìš´ ë©”ì‹œì§€ë„ chat_container ë‚´ë¶€ì— ì¶œë ¥
    with chat_container:
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant", avatar="assets/purple_avatar.png"):
            message_placeholder = st.empty()
            full_response = ""
            
            with st.status("ğŸ¤” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...", expanded=True) as status:
                
                # [Step 1] ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½
                plan = get_search_plan(prompt)
                mode = plan.get("mode", "chat")
                
                print(f"[DEBUG] Plan: {plan}")
                
                if mode == "search":
                    tasks = plan.get("tasks", [])
                    
                    task_summary = [f"{t.get('target_source').upper()}: '{t.get('keyword')}'" for t in tasks]
                    status.write(f"ğŸ“‹ **ê²€ìƒ‰ ê³„íš**: {', '.join(task_summary)}")
                    status.update(label="ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...", state="running")
                    
                    # [Step 2] í¬ë¡¤ë§ ì‹¤í–‰
                    raw_df = execute_crawling(tasks)
                    
                    if not raw_df.empty:
                        if 'Content' in raw_df.columns:
                            raw_df['Content'] = raw_df['Content'].astype(str).str.slice(0, 150)

                        initial_count = len(raw_df)
                        status.write(f"âœ… ì´ {initial_count}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
                        status.update(label="ë°ì´í„° í•„í„°ë§ ì¤‘...", state="running")
                        
                        # [Step 3] í•„í„°ë§
                        try:
                            clean_df = filter_hate_speech(raw_df)
                            target_df = clean_df.head(30)
                            
                            filtered_cnt = initial_count - len(clean_df)
                            used_cnt = len(target_df)
                            
                            status.write(f"ğŸ§¹ í•„í„°ë§: {filtered_cnt}ê±´ ì œì™¸. (ë¶„ì„ ëŒ€ìƒ: ìµœì‹  {used_cnt}ê±´)")
                                
                        except Exception as e:
                            st.warning(f"í•„í„°ë§ ì˜¤ë¥˜: {e}")
                            clean_df = raw_df
                            target_df = clean_df.head(30)
                        
                        status.update(label="ë³´ê³ ì„œ ì‘ì„± ë° í†µê³„ ë¶„ì„ ì¤‘...", state="running")
                        
                        # [Step 4] ë³´ê³ ì„œ ì‘ì„± (ìŠ¤íŠ¸ë¦¬ë°)
                        try:
                            response_stream = generate_report(prompt, target_df)
                            
                            full_buffer = ""
                            
                            for chunk in response_stream:
                                if chunk.text:
                                    full_buffer += chunk.text
                                    
                                    if "__REF_DATA__" in full_buffer:
                                        visible_text = full_buffer.split("__REF_DATA__")[0]
                                        message_placeholder.markdown(visible_text + "â–Œ")
                                    else:
                                        message_placeholder.markdown(full_buffer + "â–Œ")
                            
                            parts = full_buffer.split("__REF_DATA__")
                            report_content = parts[0].strip()
                            full_response = report_content
                            
                            ref_ids = []
                            if len(parts) > 1:
                                try:
                                    json_str = parts[1].strip().replace("```json", "").replace("```", "").strip()
                                    json_data = json.loads(json_str)
                                    
                                    ref_ids = json_data.get("reference_ids", [])
                                    sentiment_counts = json_data.get("sentiment_counts", {})
                                    topic_counts = json_data.get("topic_counts", {})
                                    
                                    # [í†µê³„ ì—…ë°ì´íŠ¸]
                                    if sentiment_counts:
                                        st.session_state.sentiment_history["Positive"] += sentiment_counts.get("Positive", 0)
                                        st.session_state.sentiment_history["Neutral"] += sentiment_counts.get("Neutral", 0)
                                        st.session_state.sentiment_history["Negative"] += sentiment_counts.get("Negative", 0)
                                        
                                    if topic_counts:
                                        st.session_state.latest_topic_counts = topic_counts
                                        
                                    # ìš°ì¸¡ ëŒ€ì‹œë³´ë“œ ë¦¬ë Œë”ë§
                                    render_stats_dashboard()

                                except json.JSONDecodeError:
                                    print(f"[DEBUG] JSON Parsing failed")

                            # ì¶”ì²œ ë§í¬
                            if ref_ids:
                                full_response += "\n\n---\n### ğŸ”— í•µì‹¬ ê²Œì‹œê¸€\n"
                                cols = {c.lower(): c for c in target_df.columns}
                                url_col = cols.get('posturl') or cols.get('url') or cols.get('link')
                                title_col = cols.get('title', 'Title')

                                if url_col:
                                    for ref_id in ref_ids:
                                        target_idx = ref_id - 1
                                        if 0 <= target_idx < len(target_df):
                                            row = target_df.iloc[target_idx]
                                            full_response += f"- [{row[title_col]}]({row[url_col]})\n"
                            
                            message_placeholder.markdown(full_response)
                            
                            # ì „ì²´ ëª©ë¡
                            if not target_df.empty:
                                status.markdown("---")
                                status.write(f"**ğŸ“‘ ë¶„ì„ì— ì‚¬ìš©ëœ ì „ì²´ ê²Œì‹œê¸€ ({len(target_df)}ê±´)**")
                                cols = {c.lower(): c for c in target_df.columns}
                                url_col = cols.get('posturl') or cols.get('url')
                                title_col = cols.get('title', 'Title')
                                
                                for i, (idx, row) in enumerate(target_df.iterrows()):
                                    status.markdown(f"{i+1}. [{row[title_col]}]({row[url_col]})")

                        except Exception as e:
                            full_response += f"\n\n(ì˜¤ë¥˜ ë°œìƒ: {str(e)})"
                            message_placeholder.markdown(full_response)

                        status.update(label="ë¶„ì„ ì™„ë£Œ! (í´ë¦­í•˜ì—¬ ì „ì²´ ëª©ë¡ í™•ì¸)", state="complete", expanded=False)
                            
                    else:
                        full_response = "ğŸ˜¥ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                        message_placeholder.markdown(full_response)
                        status.update(label="ê²€ìƒ‰ ì‹¤íŒ¨", state="error", expanded=False)
                
                else:
                    # Chat ëª¨ë“œ
                    full_response = plan.get("reply_message", "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?")
                    message_placeholder.markdown(full_response)
                    status.update(label="ëŒ€í™” ëª¨ë“œ", state="complete", expanded=False)
                    
        st.session_state.messages.append({"role": "assistant", "content": full_response})