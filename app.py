import os
import json
import time
import re
import pandas as pd
import streamlit as st
import google.generativeai as genai
import concurrent.futures
import altair as alt  # ì›í˜• ê·¸ë˜í”„ ìƒì„±ì„ ìœ„í•œ ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
from dotenv import load_dotenv

# --------------------------------------------------------------------------
# 1. ì´ˆê¸° ì„¤ì • ë° í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# --------------------------------------------------------------------------
load_dotenv()

st.set_page_config(
    page_title="íœ´ë¨¸ë‹ˆí‹° ì¸ì‚¬ì´ë“œ",
    page_icon="ğŸ•µï¸â€â™‚ï¸",
    layout="wide"
)

# ìƒˆë¡œìš´ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from src.crawler_wrapper import search_community
    from src.preprocessor import filter_hate_speech
except ImportError as e:
    # ì™¸ë¶€ ëª¨ë“ˆì´ ì—†ì„ ê²½ìš°, Streamlit ì•± ì‹¤í–‰ì„ ìœ„í•´ ë”ë¯¸ í•¨ìˆ˜ë¡œ ëŒ€ì²´
    def search_community(*args, **kwargs):
        # st.error(f"Crawler module missing. Cannot execute search for {target} - {keyword}")
        return pd.DataFrame({'Title': [f"Dummy Title - No Crawler"], 'PostUrl': ['#'], 'Content': ['Dummy content. Please install src modules.']})
    def filter_hate_speech(df):
        return df
    # st.error(f"í•„ìˆ˜ ëª¨ë“ˆì„ ì„í¬íŠ¸í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    # st.stop()


# --------------------------------------------------------------------------
# 2. ì‚¬ì´ë“œë°” ì„¤ì • (API ìƒíƒœ í‘œì‹œ)
# --------------------------------------------------------------------------
with st.sidebar:
    st.header("ğŸ“ Status")
    
    api_key = os.getenv("API_KEY")
    model_name = os.getenv("MODEL")

    if api_key and model_name:
        st.success("ğŸŸ¢ API ì—°ë™ ì •ìƒ")
        st.markdown(f"**ì‚¬ìš© ëª¨ë¸:** `{model_name}`")
    else:
        st.error("ğŸ”´ API ì—°ë™ ì‹¤íŒ¨")
        if not api_key:
            st.warning("API í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. '.env' íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        if not model_name:
            st.warning("ëª¨ë¸ ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. '.env' íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
    st.markdown("---")
    st.info("AIê°€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ì»¤ë®¤ë‹ˆí‹°(DC/Arca)ë¥¼ ì„ ì •í•˜ê³  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
    st.info("Tip) ë””ì‹œì¸ì‚¬ì´ë“œ ê²€ìƒ‰ì˜ ê¸°ë³¸ê°’ì€ í†µí•©ê²€ìƒ‰ì´ì§€ë§Œ, ê°¤ëŸ¬ë¦¬ ê²€ìƒ‰ì„ ì›í•  ê²½ìš° ì±„ë„ idì™€ í•¨ê»˜ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: í—¤ë“œí° ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬(id=newheadphone)ì—ì„œ ê²€ìƒ‰í•´ì¤˜.)")
    st.info("Tip) ë””ì‹œì¸ì‚¬ì´ë“œ í†µí•©ê²€ìƒ‰ì˜ ê¸°ë³¸ê°’ì€ ìµœì‹ ìˆœì´ì§€ë§Œ, ì •í™•ë„ ìˆœìœ¼ë¡œ ê²€ìƒ‰í•´ë‹¬ë¼ê³  í•˜ë©´ ì •í™•ë„ìˆœìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.")
    st.caption("Powered by Google Gemini")

# --------------------------------------------------------------------------
# 3. Gemini ëª¨ë¸ ë¡œë“œ 
# --------------------------------------------------------------------------
@st.cache_resource
def get_gemini_model():
    """
    Gemini ëª¨ë¸ ë¡œë“œ (ìºì‹± ì ìš©)
    """
    YOUR_API_KEY = os.getenv("API_KEY")
    if not YOUR_API_KEY:
        st.stop()

    YOUR_MODEL = os.getenv("MODEL")
    if not YOUR_MODEL:
        st.stop()
        
    genai.configure(api_key=YOUR_API_KEY)
    
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    
    return genai.GenerativeModel(YOUR_MODEL, safety_settings=safety_settings)

# --------------------------------------------------------------------------
# 4. í•µì‹¬ ë¡œì§ í•¨ìˆ˜ 
# --------------------------------------------------------------------------

def get_search_plan(user_input):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.
    """
    model = get_gemini_model()
    
    system_instruction = """
    ë„ˆëŠ” ì¸í„°ë„· ì»¤ë®¤ë‹ˆí‹°ì˜ ë¬¸í™”ì™€ ì€ì–´ì— í†µë‹¬í•œ 'ì»¤ë®¤ë‹ˆí‹° í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ìœ„í•œ ì»¤ë®¤ë‹ˆí‹° íŠ¸ë Œë“œ/ì€ì–´ ì „ë¬¸ê°€'ì•¼. 
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ ì–´ë–¤ ì»¤ë®¤ë‹ˆí‹°(DCInside, ArcaLive ë‘˜ ì¤‘ í•˜ë‚˜)ë¥¼ ì–´ë–¤ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í• ì§€ êµ¬ì²´ì ì¸ ê³„íšì„ ì„¸ì›Œì¤˜.
    
    [í•„ìˆ˜ ê·œì¹™]
    1. ì‚¬ìš©ìê°€ "ì—¬ë¡ ", "ë°˜ì‘", "í‰ê°€" , "ì˜ê²¬" , "ê·¼í™©" ë“± í‚¤ì›Œë“œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•œ ê²ƒì„ ë¬¼ìœ¼ë©´ mode="search"ë¡œ ì„¤ì •í•´.
    2. **[ê²€ìƒ‰ì–´(keyword) ì„ ì • í•µì‹¬]** - ê³µì‹ ëª…ì¹­ë³´ë‹¤ **ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì‹¤ì œë¡œ ì“°ì´ëŠ” 'ì•½ì¹­', 'ì¤„ì„ë§', 'ì€ì–´'**ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì„ íƒí•´. (ì˜ˆ: ê°¤ëŸ­ì‹œ S25 -> S25, ë¸”ë£¨ ì•„ì¹´ì´ë¸Œ -> ë¸”ì•„/ëª°ë£¨, ë¦¬ê·¸ì˜¤ë¸Œë ˆì „ë“œ -> ë¡¤)
    3. **[íƒ€ê²Ÿ ì„ ì •]** íŠ¹ì • ì‚¬ì´íŠ¸ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´, í•´ë‹¹ ì£¼ì œê°€ í™œë°œí•œ ê³³ì„ ìë™ìœ¼ë¡œ íŒë‹¨í•˜ë˜ **ì˜ ëª¨ë¥´ê² ê±°ë‚˜ ëŒ€ì¤‘ì ì¸ ê²Œì„/ì´ìŠˆë¼ë©´ ["dc", "arca"] ë‘ ê³³ì— ëŒ€í•´ taskë¥¼ ì´ 2ê°œ ìƒì„±í•´ì•¼í•´.**
    4. **task['options']ì˜ 'gallery_id'ì™€ 'gallery_type'ëŠ” ì‚¬ìš©ìê°€ íŠ¹ë³„íˆ ê°¤ëŸ¬ë¦¬ë¥¼ ì§€ì •í•˜ì§€ ì•ŠëŠ” ì´ìƒ null ê°’ì´ì•¼(í†µí•©ê²€ìƒ‰ ì´ìš©).**
    5. ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶°ì„œ ë°˜í™˜í•´ì¤˜.

    [mode íŒë‹¨ ê¸°ì¤€]
    1. "search": íŠ¹ì • ê²Œì„, ì¸ë¬¼, ì‚¬ê±´ ë“± í‚¤ì›Œë“œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•œ ì£¼ì œì— ëŒ€í•´ ë¬»ëŠ” ê²½ìš°.
    2. "clarify": í‚¤ì›Œë“œê°€ ë„ˆë¬´ ëª¨í˜¸í•´ì„œ(ì˜ˆ: 'í—¤ë¥´íƒ€'ê°€ ì‘ê°€ í—¤ë¥´íƒ€ ë®ëŸ¬ì¸ì§€, ì¶•êµ¬íŒ€ í—¤ë¥´íƒ€ BSCì¸ì§€, ë¶•ê´´ ìŠ¤íƒ€ë ˆì¼ ê²Œì„ì˜ ë“±ì¥ì¸ë¬¼ í—¤ë¥´íƒ€ì¸ì§€ ë¶ˆë¶„ëª…í•¨) ê²€ìƒ‰ ëŒ€ìƒì„ í™•ì •í•  ìˆ˜ ì—†ëŠ” ê²½ìš°.
    3. "chat": ë‹¨ìˆœ ì¸ì‚¬, ì¡ë‹´, í˜¹ì€ ë¶„ì„ê³¼ ê´€ë ¨ ì—†ëŠ” ëŒ€í™”.

    [JSON ì¶œë ¥ í˜•ì‹]
    {
        "mode": "search" | "clarify" | "chat", 
        "reply_message": "clarify" | "chat" ëª¨ë“œì¼ ë•Œ ì‚¬ìš©ìì—ê²Œ í•  ë§,
        "tasks": [
            {
                "target_source": "dc" | "arca",
                "keyword": "ê²€ìƒ‰íš¨ìœ¨ì´ ê°€ì¥ ì¢‹ì€ ìµœì ì˜ ë‹¨ì–´(ì€ì–´/ì¤„ì„ë§ ê¶Œì¥). ë¶ˆí•„ìš”í•œ ì¡°ì‚¬(ì€/ëŠ”/ì´/ê°€/ì„/ë¥¼/ì˜/ë„)ëŠ” ì œê±°í•˜ê³  ëª…ì‚¬ ìœ„ì£¼ë¡œ êµ¬ì„±.",
                "options": {
                    # dc, arca ê³µí†µ íŒŒë¼ë¯¸í„°
                    "end_page": "ì¢…ë£Œ í˜ì´ì§€ (ì»¤ë®¤ë‹ˆí‹° í•˜ë‚˜ë§Œ íƒìƒ‰í•  ë•ŒëŠ” '2', ë‘ ê³³ ëª¨ë‘(len(tasks) == 2)ì¼ ë•ŒëŠ” '1')",

                    # "target_source" == "dc" ì¼ ë•Œ ì…ë ¥í•  ë‚´ìš©
                    "gallery_id": "ê¸°ë³¸ê°’ì€ null. ì‚¬ìš©ì ìš”ì²­ì´ ìˆì„ ì‹œ í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•  ê°¤ëŸ¬ë¦¬ì˜ ê°¤ëŸ¬ë¦¬ ID (ì˜ˆ: 'maplestory_new', 'leagueoflegends6', 'chzzk').",
                    "gallery_type": "ê¸°ë³¸ê°’ì€ null. ì‚¬ìš©ìì˜ ìš”ì²­ì´ ìˆì„ ì‹œ gallery_idê°’ì— í•´ë‹¹í•˜ëŠ” ê°¤ëŸ¬ë¦¬ì˜ ì¢…ë¥˜ë¥¼ ê¸°ì¬. ('major' | 'minor').", 
                    "sort_type": ê¸°ë³¸ê°’ì€ "latest". ì‚¬ìš©ìì˜ 'ì •í™•ë„ ìˆœ' ìš”ì²­ì´ ìˆì„ ì‹œ "accuracy".

                    # "target_source" == "arca" ì¼ ë•Œ ì…ë ¥í•  ë‚´ìš©
                    "channel_id": "breaking" (í•­ìƒ í†µí•©ê²€ìƒ‰ ì‚¬ìš©),
                }
            }
        ]
    }
    """
    
    try:
        response = model.generate_content(
            f"{system_instruction}\n\nUser Input: {user_input}",
            generation_config={"response_mime_type": "application/json"}
        )
        if response.parts:
            return json.loads(response.text)
        else:
            return {"mode": "chat", "reply_message": "ì£„ì†¡í•©ë‹ˆë‹¤. ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "tasks": []}
    except Exception as e:
        return {"mode": "chat", "reply_message": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", "tasks": []}

def execute_crawling(tasks):
    """
    ìˆ˜ë¦½ëœ ê³„íš(tasks)ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    """
    all_results = []
    
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_to_task = {}
        for task in tasks:
            target = task.get("target_source")
            keyword = task.get("keyword")
            options = task.get("options", {})
            
            # ë””ë²„ê¹…: ì „ë‹¬ë˜ëŠ” íŒŒë¼ë¯¸í„° ì¶œë ¥
            print(f"[DEBUG] Crawling Task: {target} - {keyword}")
            future = executor.submit(search_community, target, keyword, **options)
            future_to_task[future] = task

        # [ìˆ˜ì •] ëª¨ë“  íƒœìŠ¤í¬ê°€ 'ì™„ì „íˆ' ëë‚  ë•Œê¹Œì§€ ëª…ì‹œì ìœ¼ë¡œ ëŒ€ê¸° (wait)
        # return_when=ALL_COMPLETEDë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ë‚˜ë¼ë„ ì‹¤í–‰ ì¤‘ì´ë©´ ë„˜ì–´ê°€ì§€ ì•ŠìŒ
        if future_to_task:
            concurrent.futures.wait(future_to_task.keys(), return_when=concurrent.futures.ALL_COMPLETED)
            
        # ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œëœ í›„ ê²°ê³¼ ìˆ˜ì§‘
        for future in future_to_task:
            try:
                df = future.result()
                current_task = future_to_task[future]
                print(f"[DEBUG] Crawling result for {current_task.get('target_source')}: {len(df)} rows")
                if not df.empty:
                    df["Source"] = current_task.get("target_source")
                    df["Keyword"] = current_task.get("keyword")
                    all_results.append(df)
                else:
                    print(f"[DEBUG] Empty DataFrame returned for {current_task.get('target_source')}")

            except Exception as e:
                print(f"[DEBUG] Error: {e}", flush=True)

    if all_results:
        # [ìˆ˜ì •] ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ë°ì´í„°ë¥¼ ê³ ë¥´ê²Œ ì„ê¸° (Interleaving)
        # ê° ë°ì´í„°í”„ë ˆì„ì— ìˆœìœ„(Rank)ë¥¼ ë§¤ê²¨ì„œ, 1ë“±ë¼ë¦¬, 2ë“±ë¼ë¦¬ ëª¨ì´ë„ë¡ ì •ë ¬
        for df in all_results:
            df['__rank'] = range(len(df))
        
        final_df = pd.concat(all_results, ignore_index=True)
        # Rank ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì†ŒìŠ¤ ê°„ ê· í˜• ë§ì¶¤ (ì˜ˆ: DC 1ìœ„ -> Arca 1ìœ„ -> DC 2ìœ„ ...)
        final_df = final_df.sort_values('__rank').drop(columns=['__rank']).reset_index(drop=True)
        
        return final_df
    else:
        return pd.DataFrame()

def generate_report(user_input, df):
    model = get_gemini_model()
    
    if df.empty: return None
        
    summary_text = ""
    cols = {c.lower(): c for c in df.columns}
    title_col = cols.get('title', 'Title')
    content_col = cols.get('content', 'Content')

    # ì¸ë±ìŠ¤ 1ë¶€í„° ì‹œì‘ (30ê°œ ì œí•œ)
    for i, (idx, row) in enumerate(df.head(30).iterrows()):
        title = row.get(title_col, "No Title")
        # ë³¸ë¬¸ 150ì ì œí•œ (ì´ë¯¸ ì˜ë ¤ìˆê² ì§€ë§Œ ì•ˆì „ì¥ì¹˜ ë° í”„ë¡¬í”„íŠ¸ ìµœì í™”)
        content = str(row.get(content_col, ""))[:150]
        # IDë¥¼ 1ë¶€í„° ì‹œì‘í•˜ëŠ” ìˆœë²ˆìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬
        summary_text += f"[ID: {i + 1}] {title}: {content}\n"
        
    prompt = f"""
    ë‹¹ì‹ ì€ ì»¤ë®¤ë‹ˆí‹° ì—¬ë¡  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    
    [ì‚¬ìš©ì ì§ˆë¬¸]
    {user_input}
    
    [ìˆ˜ì§‘ëœ ë°ì´í„° ìš”ì•½ (ID í¬í•¨)]
    {summary_text}
    
    ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    **ğŸ”¥ [ì¤‘ìš” ì§€ì¹¨] ğŸ”¥**
    ë³´ê³ ì„œì˜ ë¬¸ì¥ì´ë‚˜ í•µì‹¬ì ì¸ ì—¬ë¡ (ê¸ì •/ë¶€ì • ìš”ì†Œ)ì„ ì–¸ê¸‰í•  ë•ŒëŠ”, í•´ë‹¹ ë‚´ìš©ì˜ ê·¼ê±°ê°€ ëœ [ìˆ˜ì§‘ëœ ë°ì´í„° ìš”ì•½]ì˜ **ê²Œì‹œë¬¼ IDë¥¼ ë°˜ë“œì‹œ ê´„í˜¸ ì•ˆì— [ID] í˜•íƒœë¡œ ëª…ì‹œ**í•´ ì£¼ì„¸ìš”.
    * **ì˜ˆì‹œ:** "ëŒ€ë¶€ë¶„ì˜ ìœ ì €ê°€ ì¸í„°í˜ì´ìŠ¤ì˜ í¸ì˜ì„±ì„ ë†’ì´ í‰ê°€í–ˆìŠµë‹ˆë‹¤ [1, 5, 10]."
    * **ì˜ˆì‹œ:** "ê°€ê²© ì •ì±…ì— ëŒ€í•œ ë¶ˆë§Œì´ ë‹¤ìˆ˜ ì œê¸°ë˜ì—ˆìŠµë‹ˆë‹¤ [2, 4, 11]."
    
    [ë³´ê³ ì„œ í¬í•¨ í•­ëª©]
    1. **3ì¤„ ìš”ì•½**: ì „ì²´ì ì¸ ì—¬ë¡ ì˜ í•µì‹¬ ìš”ì•½
    2. **ê¸ì • ì—¬ë¡ **: ìœ ì €ë“¤ì´ ê¸ì •ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ìš”ì†Œ
    3. **ë¶€ì • ì—¬ë¡ **: ìœ ì €ë“¤ì´ ë¶ˆë§Œì´ë‚˜ ë¹„íŒì„ ì œê¸°í•˜ëŠ” ìš”ì†Œ
    4. **ì£¼ìš” ë…¼ìŸ**: í˜„ì¬ ê°€ì¥ ëœ¨ê±°ìš´ ê°ìë‚˜ ë…¼ìŸê±°ë¦¬
    5. **ì¢…í•© í‰ê°€**: ê²°ë¡  ë° ì œì–¸
    
    [íŠ¹ë³„ ì§€ì‹œì‚¬í•­ - ë°ì´í„° êµ¬ì¡°]
    **ì¤‘ìš”:** ë³´ê³ ì„œ ë³¸ë¬¸ ì‘ì„±ì´ ëª¨ë‘ ëë‚˜ë©´, ë°˜ë“œì‹œ `__REF_DATA__` ë¼ëŠ” êµ¬ë¶„ìë¥¼ ì¶œë ¥í•˜ê³ , ê·¸ ë’¤ì— **JSON í˜•ì‹**ìœ¼ë¡œ ì•„ë˜ ì •ë³´ë“¤ì„ ì¶œë ¥í•´ì£¼ì„¸ìš”.
    
    1. **reference_ids**: ë¶„ì„ì— ê°€ì¥ ì˜ì–‘ê°€ê°€ ë†’ì•˜ë˜ ê¸€ì˜ ID (ìµœëŒ€ 3ê°œ, ìˆ«ì ë¦¬ìŠ¤íŠ¸)
    2. **sentiment_counts**: ì „ì²´(ìµœëŒ€ 30ê°œ) ê¸€ì— ëŒ€í•œ ê°ì„± ë¶„ì„ í†µê³„. ê°ê°ì˜ ê¸€ì— ëŒ€í•´ ("Positive"|"Negative"|"Neutral")ì„ íŒë‹¨í•¨. (ê¸ì • ë¶€ì • íŒë‹¨ì´ ë¶ˆê°€ëŠ¥í•  ê²½ìš°ì—ëŠ” "Neutral"ë¡œ íŒë‹¨)
    3. **topic_counts**: ì „ì²´(ìµœëŒ€ 30ê°œ) ê¸€ì—ì„œ ì£¼ë¡œ ë‹¤ë¤„ì§„ ìƒìœ„ í‚¤ì›Œë“œ(í•œêµ­ì–´ë¡œ ì‘ì„±) 3~5ê°œì™€ ê·¸ ë¹ˆë„ìˆ˜
    
    __REF_DATA__
    {{
        "reference_ids": [1, 5, 10],
        "sentiment_counts": {{ "Positive": 12, "Negative": 8, "Neutral": 10 }},
        "topic_counts": {{ "ê²Œì„í”Œë ˆì´": 15, "ìŠ¤í† ë¦¬": 8, "ìš´ì˜": 7 }}
    }}
    """
    
    return model.generate_content(prompt, stream=True)

# ==========================================================================
# 5. ë©”ì¸ ë¡œì§ 
# ==========================================================================

# [CSS] ìŠ¤íƒ€ì¼ ë³‘í•© (ê¸°ì¡´ ë ˆì´ì•„ì›ƒ CSS + í˜‘ì—…ì CSS)
st.markdown("""
<style>
    /* í˜‘ì—…ì ì¶”ê°€ ìŠ¤íƒ€ì¼ */
    .main-header {
        font-size: 2.5rem !important;
        font-weight: 700 !important;
        color: #333399 !important;
        margin-bottom: 0px !important;
    }
    .sub-header {
        font-size: 1.1rem !important;
        color: #666 !important;
        margin-top: -10px !important;
        margin-bottom: 20px !important;
    }
    div.stButton > button {
        width: 100% !important;
        border-radius: 20px !important;
        border: 1px solid #ddd !important;
    }
    /* ë‹¤í¬ëª¨ë“œ/ë¼ì´íŠ¸ëª¨ë“œ ëŒ€ì‘ í…ìŠ¤íŠ¸ ì»¬ëŸ¬ ì¡°ì • (ì˜µì…˜) */
    @media (prefers-color-scheme: dark) {
        .main-header { color: #8080ff !important; }
        .sub-header { color: #cccccc !important; }
    }
    </style>
""", unsafe_allow_html=True)

# [Header] í˜‘ì—…ì ë””ìì¸ ì ìš©
st.markdown("""
    <div style="text-align: left;">
        <h1 class="main-header">ğŸŒ íœ´ë¨¸ë‹ˆí‹° ì¸ì‚¬ì´ë“œ ğŸ”</h1>
        <p class="sub-header">ì»¤ë®¤ë‹ˆí‹°ì˜ ì¸ê°„ë¯¸ ë„˜ì¹˜ëŠ”(Humanity) ì´ìš©ì(Inside)ì˜ ì†”ì§í•œ ê¸€ì„ ë°”íƒ•ìœ¼ë¡œ, ì§„ì •ì„± ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤</p>
    </div>
    <hr style="margin-top: 0; margin-bottom: 30px;">
""", unsafe_allow_html=True)

# [Session State] ì´ˆê¸°í™”
if "search_history" not in st.session_state:
    st.session_state.search_history = []  # ê²€ìƒ‰ ê¸°ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
if "current_view_index" not in st.session_state:
    st.session_state.current_view_index = -1 # í˜„ì¬ ë³´ê³  ìˆëŠ” ê²€ìƒ‰ ê¸°ë¡ì˜ ì¸ë±ìŠ¤

if "messages" not in st.session_state:
    st.session_state.messages = []
    # í˜‘ì—…ì í™˜ì˜ ë©”ì‹œì§€ ì ìš©
    welcome_msg = "ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ê²Œì„, ì¸ë¬¼, ì´ìŠˆ ë“±ì„ ë¬¼ì–´ë´ì£¼ì„¸ìš”. ì œê°€ ì»¤ë®¤ë‹ˆí‹°ì˜ ê´€ë ¨ ë‚´ìš©ì„ ì¢…í•©í•´ë“œë¦´ê²Œìš”!"
    st.session_state.messages.append({"role": "assistant", "content": welcome_msg})

# --- í™”ë©´ ë ˆì´ì•„ì›ƒ ë¶„í•  (ì¢Œ: ì±„íŒ… / ìš°: í†µê³„) ---
chat_col, stat_col = st.columns([0.6, 0.4], gap="large")

# ëŒ€ì‹œë³´ë“œ Placeholder
dashboard_placeholder = stat_col.empty()

# [ìš°ì¸¡] í†µê³„ ëŒ€ì‹œë³´ë“œ ë Œë”ë§ í•¨ìˆ˜
def render_stats_dashboard():
    with dashboard_placeholder.container():
        st.markdown("### ğŸ“ˆ ì‹¤ì‹œê°„ ì—¬ë¡  ëŒ€ì‹œë³´ë“œ")
        
        # ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€ ì¶œë ¥
        if not st.session_state.search_history:
            st.info("ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ë©´ í†µê³„ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            return

        # í˜„ì¬ ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬ ë° ë³´ì •
        if st.session_state.current_view_index < 0 or st.session_state.current_view_index >= len(st.session_state.search_history):
             st.session_state.current_view_index = len(st.session_state.search_history) - 1
        
        idx = st.session_state.current_view_index
        history_item = st.session_state.search_history[idx]
        
        # [ë„¤ë¹„ê²Œì´ì…˜ UI] ì´ì „/ë‹¤ìŒ ë²„íŠ¼ ë° í˜„ì¬ ìƒíƒœ í‘œì‹œ
        nav_col1, nav_col2, nav_col3 = st.columns([0.2, 0.6, 0.2])
        
        with nav_col1:
            if idx > 0:
                # ì´ì „ ë²„íŠ¼: ì¸ë±ìŠ¤ ê°ì†Œ callback
                st.button("â—€", key=f"prev_{idx}", on_click=lambda: setattr(st.session_state, 'current_view_index', idx - 1))
        
        with nav_col3:
            if idx < len(st.session_state.search_history) - 1:
                # ë‹¤ìŒ ë²„íŠ¼: ì¸ë±ìŠ¤ ì¦ê°€ callback
                st.button("â–¶", key=f"next_{idx}", on_click=lambda: setattr(st.session_state, 'current_view_index', idx + 1))
        
        with nav_col2:
            # í°íŠ¸ í¬ê¸° ìˆ˜ì •: 1.5emìœ¼ë¡œ í‚¤ì›€
            st.markdown(f"<div style='text-align: center; font-weight: bold; font-size: 1.5em; margin-top: 5px;'>{history_item['label']}<br><span style='color:gray; font-size:0.8em;'>({idx + 1}/{len(st.session_state.search_history)})</span></div>", unsafe_allow_html=True)

        st.markdown("---")

        # 1. ëˆ„ì  ê°ì„± ë¶„ì„ (ì›í˜• ê·¸ë˜í”„)
        # ì„ íƒëœ íˆìŠ¤í† ë¦¬ ì•„ì´í…œì˜ ê°ì„± ë°ì´í„° ì‚¬ìš©
        sentiment_counts = history_item.get("sentiment", {})
        total_sentiment = sum(sentiment_counts.values()) if sentiment_counts else 0
        
        if total_sentiment > 0:
            st.markdown("#### ğŸ˜Š ê°ì„± ë¹„ìœ¨")
            sentiment_df = pd.DataFrame([
                {"Category": "ğŸ˜Š ê¸ì •", "Count": sentiment_counts.get("Positive", 0)},
                {"Category": "ğŸ˜ ì¤‘ë¦½", "Count": sentiment_counts.get("Neutral", 0)},
                {"Category": "ğŸ˜¡ ë¶€ì •", "Count": sentiment_counts.get("Negative", 0)}
            ])
            
            base = alt.Chart(sentiment_df).encode(theta=alt.Theta("Count", stack=True))
            pie = base.mark_arc(outerRadius=120, innerRadius=60).encode(
                color=alt.Color("Category", scale=alt.Scale(domain=["ğŸ˜Š ê¸ì •", "ğŸ˜ ì¤‘ë¦½", "ğŸ˜¡ ë¶€ì •"], range=["#66BB6A", "#FFCA28", "#EF5350"])),
                order=alt.Order("Count", sort="descending"),
                tooltip=["Category", "Count"]
            )
            text = base.mark_text(radius=140).encode(
                text="Count", order=alt.Order("Count", sort="descending"), color=alt.value("black"), size=alt.value(16)
            )
            st.altair_chart(pie + text, width='stretch')
            
            c1, c2, c3 = st.columns(3)
            c1.metric("ê¸ì •", sentiment_counts.get("Positive", 0))
            c2.metric("ì¤‘ë¦½", sentiment_counts.get("Neutral", 0))
            c3.metric("ë¶€ì •", sentiment_counts.get("Negative", 0))
        else:
            st.info("ê°ì„± ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")

        # 2. í‚¤ì›Œë“œ ë¹ˆë„ (ë§‰ëŒ€ ê·¸ë˜í”„)
        # ì„ íƒëœ íˆìŠ¤í† ë¦¬ ì•„ì´í…œì˜ í† í”½ ë°ì´í„° ì‚¬ìš©
        topic_counts = history_item.get("topics", {})
        
        if topic_counts:
            st.markdown("#### ğŸ”‘ í‚¤ì›Œë“œ ë¹ˆë„")
            topic_df = pd.DataFrame(list(topic_counts.items()), columns=['Keyword', 'Count']).sort_values(by='Count', ascending=False)
            
            bar = alt.Chart(topic_df).mark_bar().encode(
                x=alt.X('Count', title='ë¹ˆë„ìˆ˜'),
                y=alt.Y('Keyword', sort='-x', title='í‚¤ì›Œë“œ'),
                color=alt.value("#7E57C2"),
                tooltip=['Keyword', 'Count']
            ).properties(height=300)
            
            st.altair_chart(bar, width='stretch')
        else:
            st.caption("í‚¤ì›Œë“œ í†µê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì´ˆê¸° ë Œë”ë§
render_stats_dashboard()

# [ì¢Œì¸¡] ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
with chat_col:
    # ë†’ì´ ê³ ì • ì»¨í…Œì´ë„ˆ
    chat_container = st.container(height=950)
    
    with chat_container:
        # ë©”ì‹œì§€ ì¶œë ¥ (í˜‘ì—…ì ì•„ë°”íƒ€ ì ìš©)
        for message in st.session_state.messages:
            avatar_img = "ğŸ•µï¸" if message["role"] == "assistant" else "ğŸ’â€â™‚ï¸"
            with st.chat_message(message["role"], avatar=avatar_img):
                st.markdown(message["content"])
                
                # [ìˆ˜ì • 2] ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ë£¨í”„ì—ì„œ Expander ë Œë”ë§
                # ì´ì „ ê²€ìƒ‰ ê²°ê³¼ì˜ ëª©ë¡ë„ ì—¬ê¸°ì„œ ë³´ì¡´ë˜ì–´ ì¶œë ¥ë©ë‹ˆë‹¤.
                if "references" in message and isinstance(message["references"], pd.DataFrame) and not message["references"].empty:
                    with st.expander(f"ğŸ“š ì‚¬ìš©ëœ ì „ì²´ ê²Œì‹œê¸€ ë³´ê¸° ({len(message['references'])}ê±´)"):
                        df_ref = message["references"]
                        cols = {c.lower(): c for c in df_ref.columns}
                        url_col = cols.get('posturl') or cols.get('url') or cols.get('link')
                        title_col = cols.get('title', 'Title')
                        for i, (idx, row) in enumerate(df_ref.iterrows()):
                            st.markdown(f"**{i+1}.** [{row[title_col]}]({row[url_col]}) ({row.get('Source', '')})")

    # ì…ë ¥ ì²˜ë¦¬ ë¡œì§ (ë²„íŠ¼ ë° Chat Input)
    # Chat Inputì€ í•­ìƒ í•˜ë‹¨ì— ìœ„ì¹˜
    user_input = st.chat_input("ë¬´ì—‡ì„ ë¶„ì„í•´ ë“œë¦´ê¹Œìš”?")
    
    # ì¶”ì²œ í‚¤ì›Œë“œ ë²„íŠ¼ (ë©”ì‹œì§€ê°€ ì ì„ ë•Œë§Œ í‘œì‹œ)
    # ë²„íŠ¼ í´ë¦­ ì‹œ prompt ë³€ìˆ˜ì— ê°’ì„ í• ë‹¹í•˜ì—¬ user_inputì´ ìˆëŠ” ê²ƒì²˜ëŸ¼ ì²˜ë¦¬
    prompt = None
    
    if len(st.session_state.messages) < 2:
        with chat_container:
            st.caption("ğŸ”¥ ìš”ì¦˜ í•«í•œ í‚¤ì›Œë“œ / ì¶”ì²œ ì§ˆë¬¸")
            col1, col2, col3, col4 = st.columns(4)
            if col1.button("ğŸ® ë¡¤ë“œì»µ ë°˜ì‘"):
                prompt = "ì´ë²ˆ ë¡¤ë“œì»µ ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ ì•Œë ¤ì¤˜"
            if col2.button("ğŸ“± ì•„ì´í° 16 í›„ê¸°"):
                prompt = "ì•„ì´í° 16 ì‹¤ì‚¬ìš© í›„ê¸° ìš”ì•½í•´ì¤˜"
            if col3.button("âš½ ì†í¥ë¯¼ í˜„ì§€ ë°˜ì‘"):
                prompt = "ì†í¥ë¯¼ ìµœê·¼ ê²½ê¸° í˜„ì§€ ë° êµ­ë‚´ ë°˜ì‘"
            if col4.button("ğŸ‘©â€ğŸ³â€ í‘ë°±ìš”ë¦¬ì‚¬ ì—¬ë¡ "):
                prompt = "ë„·í”Œë¦­ìŠ¤ í‘ë°±ìš”ë¦¬ì‚¬ í”„ë¡œê·¸ë¨ ì—¬ë¡  ì•Œë ¤ì¤˜"
    
    # ì…ë ¥ ìš°ì„ ìˆœìœ„: Chat Input > Button Input
    if user_input:
        prompt = user_input

    # [Main Logic] ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # chat_container ë‚´ì— ì¶œë ¥
        with chat_container:
            with st.chat_message("user", avatar="ğŸ’â€â™‚ï¸"):
                st.markdown(prompt)

            # AI ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant", avatar="ğŸ•µï¸"):
                message_placeholder = st.empty()
                full_response = ""
                
                # í˜‘ì—…ì ìƒíƒœ í‘œì‹œ ë¡œì§ ì ìš©
                with st.status("ğŸ•µï¸ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...", expanded=True) as status:
                    
                    # [Step 1] ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½
                    plan = get_search_plan(prompt)
                    mode = plan.get("mode", "chat")
                    
                    if mode == "search":
                        tasks = plan.get("tasks", [])
                        
                        task_summary = [f"{t.get('target_source').upper()}: '{t.get('keyword')}'" for t in tasks]
                        status.write(f"ğŸ“‹ **ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ**: {', '.join(task_summary)}")
                        status.update(label="ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...", state="running")
                        
                        # [Step 2] í¬ë¡¤ë§ ì‹¤í–‰
                        raw_df = execute_crawling(tasks)
                        
                        if not raw_df.empty:
                            if 'Content' in raw_df.columns:
                                raw_df['Content'] = raw_df['Content'].astype(str).str.slice(0, 150)

                            initial_count = len(raw_df)
                            status.write(f"âœ… ì´ {initial_count}ê±´ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
                            status.update(label="í˜ì˜¤ í‘œí˜„ì„ í•„í„°ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤...", state="running")
                            
                            # [Step 3] í˜ì˜¤ í‘œí˜„ í•„í„°ë§
                            try:
                                clean_df = filter_hate_speech(raw_df)
                                target_df = clean_df.head(30) # ìµœì‹  30ê±´ ì‚¬ìš©
                                
                                # target_dfë¥¼ ë¡œì»¬ ë³€ìˆ˜ë¡œ ì‚¬ìš© (ë©”ì‹œì§€ì— ì €ì¥ë¨)
                                
                                filtered_cnt = initial_count - len(clean_df)
                                used_cnt = len(target_df)
                                
                                msg = f"ğŸ§¹ **í•„í„°ë§ ì™„ë£Œ**: {filtered_cnt}ê±´ì˜ ë¶€ì ì ˆí•œ ê²Œì‹œë¬¼ì„ ì œì™¸í–ˆìŠµë‹ˆë‹¤. (ë¶„ì„ ëŒ€ìƒ: ìµœê·¼ {used_cnt}ê±´)"
                                status.write(msg)
                                    
                            except Exception as e:
                                st.warning(f"í•„í„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                                clean_df = raw_df
                                target_df = clean_df.head(30)
                            
                            status.update(label="ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...", state="running")
                            
                            # [Step 4] ë³´ê³ ì„œ ì‘ì„± (ìŠ¤íŠ¸ë¦¬ë°)
                            try:
                                response_stream = generate_report(prompt, target_df)
                                
                                full_buffer = ""
                                
                                for chunk in response_stream:
                                    if chunk.text:
                                        full_buffer += chunk.text
                                        
                                        if "__REF_DATA__" in full_buffer:
                                            visible_text = full_buffer.split("__REF_DATA__")[0]
                                            message_placeholder.markdown(visible_text + "â–Œ")
                                        else:
                                            message_placeholder.markdown(full_buffer + "â–Œ")
                            
                                parts = full_buffer.split("__REF_DATA__")
                                report_content = parts[0].strip()
                                full_response = report_content
                                
                                # í†µê³„ ë°ì´í„° ì²˜ë¦¬
                                ref_ids = []
                                if len(parts) > 1:
                                    try:
                                        json_str = parts[1].strip().replace("```json", "").replace("```", "").strip()
                                        json_data = json.loads(json_str)
                                        
                                        ref_ids = json_data.get("reference_ids", [])
                                        sentiment_counts = json_data.get("sentiment_counts", {})
                                        topic_counts = json_data.get("topic_counts", {})
                                        
                                        # [ìˆ˜ì •] í†µê³„ë¥¼ search_historyì— ì¶”ê°€ (History Logic)
                                        sources = set([t.get('target_source').upper() for t in tasks])
                                        keywords = set([t.get('keyword') for t in tasks])
                                        label = f"{', '.join(sources)} - {', '.join(keywords)}"
                                        
                                        new_history_item = {
                                            "label": label,
                                            "timestamp": time.time(),
                                            "sentiment": sentiment_counts,
                                            "topics": topic_counts
                                        }
                                        
                                        st.session_state.search_history.append(new_history_item)
                                        # ì¸ë±ìŠ¤ë¥¼ ê°€ì¥ ìµœì‹ (ë§ˆì§€ë§‰)ìœ¼ë¡œ ì´ë™
                                        st.session_state.current_view_index = len(st.session_state.search_history) - 1
                                            
                                        # ìš°ì¸¡ ëŒ€ì‹œë³´ë“œ ë¦¬ë Œë”ë§
                                        render_stats_dashboard()

                                    except json.JSONDecodeError:
                                        print(f"[DEBUG] JSON Parsing failed")

                                # [UI êµ¬ì„± 1] ì¶”ì²œ ë§í¬ ì¶”ê°€
                                if ref_ids:
                                    full_response += "\n\n---\n### ğŸ”— Geminiê°€ ì°¸ê³ í•œ í•µì‹¬ ê²Œì‹œê¸€\n"
                                    cols = {c.lower(): c for c in target_df.columns}
                                    url_col = cols.get('posturl') or cols.get('url') or cols.get('link')
                                    title_col = cols.get('title', 'Title')

                                    if url_col:
                                        for ref_id in ref_ids:
                                            target_idx = ref_id - 1
                                            if 0 <= target_idx < len(target_df):
                                                row = target_df.iloc[target_idx]
                                                full_response += f"- [{row[title_col]}]({row[url_col]})\n"
                            
                                message_placeholder.markdown(full_response)
                                
                                # [ìˆ˜ì •] Expander ì¦‰ì‹œ ë Œë”ë§ (Rerun ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŒ)
                                if not target_df.empty:
                                    with st.expander(f"ğŸ“š ì‚¬ìš©ëœ ì „ì²´ ê²Œì‹œê¸€ ë³´ê¸° ({len(target_df)}ê±´)"):
                                        cols = {c.lower(): c for c in target_df.columns}
                                        url_col = cols.get('posturl') or cols.get('url') or cols.get('link')
                                        title_col = cols.get('title', 'Title')
                                        for i, (idx, row) in enumerate(target_df.iterrows()):
                                            st.markdown(f"**{i+1}.** [{row[title_col]}]({row[url_col]}) ({row.get('Source', '')})")

                            except Exception as e:
                                full_response += f"\n\n(ì˜¤ë¥˜ ë°œìƒ: {str(e)})"
                                message_placeholder.markdown(full_response)

                            status.update(label="ë¶„ì„ ì™„ë£Œ! (ì•„ë˜ì—ì„œ ì „ì²´ ëª©ë¡ì„ í™•ì¸í•˜ì„¸ìš”)", state="complete", expanded=False)
                                
                        else:
                            full_response = "ğŸ˜¥ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                            message_placeholder.markdown(full_response)
                            status.update(label="ê²€ìƒ‰ ì‹¤íŒ¨", state="error", expanded=False)
                    
                    else:
                        # Chat ëª¨ë“œ
                        full_response = plan.get("reply_message", "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?")
                        message_placeholder.markdown(full_response)
                        status.update(label="ëŒ€í™” ëª¨ë“œ", state="complete", expanded=False)
            
            # [ìˆ˜ì • 2 ê´€ë ¨] target_dfë¥¼ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— í•¨ê»˜ ì €ì¥ (references í‚¤ ì‚¬ìš©)
            msg_data = {"role": "assistant", "content": full_response}
            if mode == "search" and not raw_df.empty:
                 msg_data["references"] = target_df
            
            st.session_state.messages.append(msg_data)
            
            # ë²„íŠ¼ í´ë¦­ ë“±ìœ¼ë¡œ ì¸í•´ ê°±ì‹ ëœ ê²½ìš° reruní•˜ì—¬ UI ì—…ë°ì´íŠ¸
            if prompt and not user_input:
                st.rerun()