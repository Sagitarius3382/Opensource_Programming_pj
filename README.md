# 커뮤니티 크롤러 내부 API 가이드

이 문서에서는 `src/arca_scraper.py`와 `src/dc_scraper.py` 파일에 정의된 크롤러 함수에 대한 사용법을 설명합니다.

---

## 1. 환경 설정 및 설치

이 프로젝트는 Python 가상 환경을 사용하여 의존성을 관리합니다. 아래 절차를 따라 환경을 설정하세요.

1.  **가상 환경 생성**:
    ```bash
    python -m venv venv
    ```

2.  **가상 환경 활성화**:
    - Windows:
        ```bash
        .\venv\Scripts\activate
        ```
    - macOS/Linux:
        ```bash
        source venv/bin/activate
        ```

3.  **의존성 설치**:
    ```bash
    pip install -r requirements.txt
    ```

4.  **환경 변수 설정**:
    `.env.example` 파일을 복사하여 `.env` 파일을 생성하고 필요한 API 키를 입력하세요.
    ```bash
    cp .env.example .env
    ```

---

## 2. Arcalive Crawler: 아카라이브 크롤러 (`src/arca_scraper.py`)

아카라이브 채널 및 통합 검색을 통해 게시물과 댓글을 수집합니다. Selenium을 사용하여 동적 콘텐츠를 처리합니다.

> **⚠️ 경고: 본 프로그램을 사용하기 전에 아래 규정 및 고지사항을 반드시 숙지하십시오.**

### 2.1. 아카라이브 이용 규정 (발췌)

본 프로그램은 다음 아카라이브 이용 규정에 명시된 금지 행위를 위한 도구가 아닙니다.

#### <8. 기타 제한 사항>
- 서버에 부하를 주는 크롤링, 스크랩핑을 시도할 경우 사이트 이용이 제한됩니다.

---

### 2.2. 🚨 중요 고지: 프로그램 사용자의 책임 및 면책 사항 🚨

**본 프로그램을 사용하기 전에 아카라이브의 이용 규정을 반드시 숙지해야 하며, 아래의 모든 내용에 동의함을 확인합니다.**

#### 규정 위반 금지 및 사용 목적 제한
본 프로그램은 아카라이브 규정을 위반하는 목적으로 사용할 수 없습니다. 규정에 명시된 **서버에 부하를 주는 크롤링 또는 스크랩핑** 등의 행위는 **엄격히 금지**됩니다.

#### 민형사상 책임은 전적으로 사용자에게 귀속
**이 프로그램의 사용자**가 아카라이브 규정을 위반하는 행위를 하였을 경우, 이로 인해 발생하는 모든 **민형사상의 책임** 및 **법적 불이익**은 **전적으로 사용자 본인에게 있습니다.**

#### 프로그램 제작자의 면책
프로그램 제작자는 사용자의 규정 위반 행위 및 그 결과 발생하는 모든 문제(사이트 이용 제한, 손해배상 등)에 대해 **어떠한 책임도 지지 않으며**, **일절 관여하지 않습니다.**

**본 프로그램을 사용하는 행위는 상기 아카라이브 이용 규정 및 제작자의 면책 고지사항에 대해 충분히 이해하고 동의하였음을 명시적으로 확인하는 것으로 간주됩니다.**

---

### 2.3. 함수 설명 및 사용법

#### 2.3.1. 함수: `get_arca_posts`

```python
def get_arca_posts(
    channel_id: str, 
    search_keyword: str = "", 
    start_page: int = 1, 
    end_page: int = 3
) -> pd.DataFrame
```

#### 매개변수 설명

| 매개변수 | 타입 | 기본값 | 설명 |
| :--- | :--- | :--- | :--- |
| `channel_id` | `str` | *필수* | 크롤링할 채널 ID (예: `wutheringwaves`). 통합 검색 시 `breaking`, 핫딜 채널은 `hotdeal`. |
| `search_keyword` | `str` | `""` | 검색할 키워드. |
| `start_page` | `int` | `1` | 시작 페이지. |
| `end_page` | `int` | `3` | 종료 페이지. |

#### 반환 값 (DataFrame Columns)

| 컬럼명 | 설명 |
| :--- | :--- |
| `PostID` | 게시물 고유 번호 |
| `Title` | 게시물 제목 |
| `Content` | 게시물 본문 텍스트 |
| `Comments` | 댓글 내용 (번호가 매겨진 텍스트 형식) |
| `GalleryID` | 채널 ID (또는 통합 검색 시 원본 채널명) |
| `PostURL` | 게시물 원본 URL |

---
# DC Inside Data Tool - 디시인사이드 크롤러/정보 수집 도구

> **⚠️ 경고: 본 프로그램 사용 전 반드시 아래 약관 및 고지사항을 숙지하십시오.**

---

## 3. 디시인사이드 이용약관 (발췌)

본 프로그램은 다음 디시인사이드 이용약관 조항에 명시된 금지 행위를 위한 도구가 아닙니다.

### 3.1. <제11조 (이용자의 의무) 13항>

13. 자동화된 수단을 이용하여 서비스에 게재된 콘텐츠를 비롯한 기타 정보(고정닉, 닉네임, 비회원의 일부 IP 등)를 수집하거나 인공지능(AI) 학습을 목적으로 수집, 이용하는 행위

### 3.2. <제15조 (크롤링 및 인공지능 학습)>

① 회사는 robots.txt에 적용한 일부 사이트에 한해서 크롤링을 허용하고 있습니다. 당사의 사전 서면 동의 없이 어떤 형태로든 어떤 목적으로든 본 서비스를 크롤링하는 행위는 명시적으로 금지됩니다.
② 회사의 콘텐츠를 인공지능 학습용 데이터(머신러닝, 딥러닝 등 인공지능 모델 학습을 위해 활용되는 모든 데이터) 등에 활용할 경우 반드시 회사와 사전 합의해야 합니다. 공익 및 비영리 목적인 경우에도 회사의 동의를 받아야 합니다. 그렇지 않을 경우, 민형사상 책임을 물을 수 있습니다.

---

## 4. 🚨 중요 고지: 프로그램 사용자의 책임 및 면책 사항 🚨

**본 프로그램을 사용하기 전에 디시인사이드의 이용약관을 반드시 숙지해야 하며, 아래의 모든 내용에 동의함을 확인합니다.**

### 약관 위반 금지 및 사용 목적 제한
본 프로그램은 디시인사이드 이용약관을 위반하는 목적으로 사용할 수 없습니다. 약관에 명시된 **자동화된 수단을 이용한 콘텐츠 및 정보 수집**이나 **사전 동의 없는 크롤링 및 AI 학습용 데이터 수집** 등의 행위는 **명시적으로 금지**됩니다.

### 민형사상 책임은 전적으로 사용자에게 귀속
**이 프로그램의 사용자**가 디시인사이드 이용약관을 위반하는 행위를 하였을 경우, 이로 인해 발생하는 모든 **민형사상의 책임** 및 **법적 불이익**은 **전적으로 사용자 본인에게 있습니다.**

### 프로그램 제작자의 면책
프로그램 제작자는 사용자의 약관 위반 행위 및 그 결과 발생하는 모든 문제(손해배상, 법적 소송 등)에 대해 **어떠한 책임도 지지 않으며**, **일절 관여하지 않습니다.**

**본 프로그램을 사용하는 행위는 상기 디시인사이드 이용약관 조항 및 제작자의 면책 고지사항에 대해 충분히 이해하고 동의하였음을 명시적으로 확인하는 것으로 간주됩니다.**

---

## 5. 프로그램 기능 및 모듈 소개

### 5.1. DC 인사이드 크롤러 (`src/dc_scraper.py`)

이 모듈은 디시인사이드의 특정 갤러리 또는 게시물을 조회하고 데이터를 처리하는 기능을 수행합니다.

#### 5.1.1. 갤러리 목록 검색 (`get_regular_post_data`)
주요 갤러리 또는 마이너 갤러리에서 일반 게시글 데이터를 수집합니다.

```python
def get_regular_post_data(
    gallery_id: str, 
    gallery_type: str = "minor", 
    search_keyword: str = "", 
    search_option: int = 0, 
    start_page: int = 1, 
    end_page: int = 3
) -> pd.DataFrame
```

#### 매개변수 설명

| 매개변수 | 타입 | 기본값 | 설명 |
| :--- | :--- | :--- | :--- |
| `gallery_id` | `str` | *필수* | 크롤링할 갤러리의 고유 ID (예: `comic_new6`, `aion2`). |
| `gallery_type` | `str` | `"minor"` | 갤러리 유형 (`major`, `minor`, `mini` 중 하나). |
| `search_keyword` | `str` | `""` | 검색할 키워드. 미입력 시 해당 갤러리의 단순 게시글 목록을 수집합니다. |
| `search_option` | `int` | `0` | 검색 옵션 지정.<br> **0:** 제목 + 내용 검색 (기본값)<br> **1:** 제목만 검색<br> **2:** 내용만 검색 |
| `start_page` | `int` | `1` | 검색을 시작할 페이지 번호. |
| `end_page` | `int` | `3` | 검색을 종료할 페이지 번호. |

#### 반환 값 (DataFrame Columns)

| 컬럼명 | 설명 |
| :--- | :--- |
| `PostID` | 게시물 고유 번호 |
| `Title` | 게시물 제목 |
| `Content` | 게시물 본문 텍스트 |
| `GalleryID` | 갤러리 ID |
| `PostURL` | 게시물 원본 URL |

#### 5.1.2. 통합 검색 (`get_integrated_search_data`)

DC 인사이드 통합 검색 페이지를 사용하여 전체 갤러리를 대상으로 게시물을 검색하고, 개별 게시물의 본문까지 크롤링합니다.

```python
def get_integrated_search_data(
    search_keyword: str, 
    sort_type: str = "latest", 
    start_page: int = 1, 
    end_page: int = 3
) -> pd.DataFrame
```

#### 매개변수 설명

| 매개변수 | 타입 | 기본값 | 설명 |
| :--- | :--- | :--- | :--- |
| `search_keyword` | `str` | *필수* | 통합 검색에 사용할 키워드. |
| `sort_type` | `str` | `"latest"` | 검색 결과 정렬 방식.<br> **"latest":** 최신순 (기본값)<br> **"accuracy":** 정확도순 |
| `start_page` | `int` | `1` | 검색을 시작할 페이지 번호. |
| `end_page` | `int` | `3` | 검색을 종료할 페이지 번호. |

#### 반환 값 (DataFrame Columns)

| 컬럼명 | 설명 |
| :--- | :--- |
| `PostID` | 게시물 고유 번호 |
| `Title` | 게시물 제목 |
| `Content` | 게시물 본문 텍스트 |
| `GalleryID` | 갤러리 ID |
| `GalleryName` | 갤러리 이름 |
| `PostURL` | 게시물 원본 URL |

---
